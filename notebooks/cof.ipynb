{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n",
      "/raid6/homes/kierannp/.conda/envs/ml/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-07 13:47:51.839745: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-07 13:47:52.746412: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/mpi/gcc/openmpi-4.1.2/lib\n",
      "2023-02-07 13:47:52.746511: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/mpi/gcc/openmpi-4.1.2/lib\n",
      "2023-02-07 13:47:52.746521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import mbuild as mb\n",
    "import parmed\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.loader import DataLoader\n",
    "import shutil\n",
    "import rdkit \n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/raid6/homes/kierannp/projects/multi-egnn\")\n",
    "from megnn.datasets import *\n",
    "from megnn.megnn import *\n",
    "from megnn.utils import *\n",
    "\n",
    "# try:\n",
    "#     shutil.rmtree('./processed')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "n_epochs  = 30\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.float32\n",
    "batch_size = 32\n",
    "\n",
    "# dataset\n",
    "dat = COF_Dataset(root='.')\n",
    "dat.shuffle()\n",
    "train_dataset = dat[:int(len(dat)*.8)]\n",
    "test_dataset = dat[int(len(dat)*.8):]\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, follow_batch=['x_s', 'x_t', 'positions_s', 'positions_t'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, follow_batch=['x_s', 'x_t', 'positions_s', 'positions_t'], shuffle=False)\n",
    "\n",
    "# model\n",
    "model = MEGNN(n_graphs=2, in_node_nf=110, in_edge_nf=0, hidden_nf=64, device=device, n_layers=7, coords_weight=1.0,\n",
    "             attention=True, node_attr=1)\n",
    "\n",
    "# optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t Iteration 0 \t loss 2130.7080\n",
      "Epoch 0 \t Iteration 10 \t loss 55.3238\n",
      "Epoch 0 \t Iteration 20 \t loss 1162.7804\n",
      "Epoch 0 \t Iteration 30 \t loss 290.5831\n",
      "Epoch 0 \t Iteration 40 \t loss 23.4714\n",
      "Epoch 0 \t Iteration 50 \t loss 19.8606\n",
      "test loss: 304.5676 \t epoch 0\n",
      "Best: val loss: 304.5676 \t test loss: 304.5676 \t epoch 0\n",
      "Epoch 1 \t Iteration 0 \t loss 10.1445\n",
      "Epoch 1 \t Iteration 10 \t loss 13.3259\n",
      "Epoch 1 \t Iteration 20 \t loss 8.8286\n",
      "Epoch 1 \t Iteration 30 \t loss 1.4462\n",
      "Epoch 1 \t Iteration 40 \t loss 0.6428\n",
      "Epoch 1 \t Iteration 50 \t loss 0.9357\n",
      "test loss: 69.1354 \t epoch 1\n",
      "Best: val loss: 69.1354 \t test loss: 69.1354 \t epoch 1\n",
      "Epoch 2 \t Iteration 0 \t loss 0.5056\n",
      "Epoch 2 \t Iteration 10 \t loss 0.2776\n",
      "Epoch 2 \t Iteration 20 \t loss 0.5622\n",
      "Epoch 2 \t Iteration 30 \t loss 0.9675\n",
      "Epoch 2 \t Iteration 40 \t loss 1.5211\n",
      "Epoch 2 \t Iteration 50 \t loss 0.1066\n",
      "test loss: 75.0765 \t epoch 2\n",
      "Best: val loss: 69.1354 \t test loss: 69.1354 \t epoch 1\n",
      "Epoch 3 \t Iteration 0 \t loss 0.4877\n",
      "Epoch 3 \t Iteration 10 \t loss 0.4631\n",
      "Epoch 3 \t Iteration 20 \t loss 0.4680\n",
      "Epoch 3 \t Iteration 30 \t loss 0.6268\n",
      "Epoch 3 \t Iteration 40 \t loss 0.3148\n",
      "Epoch 3 \t Iteration 50 \t loss 0.2061\n",
      "test loss: 25.4002 \t epoch 3\n",
      "Best: val loss: 25.4002 \t test loss: 25.4002 \t epoch 3\n",
      "Epoch 4 \t Iteration 0 \t loss 0.1548\n",
      "Epoch 4 \t Iteration 10 \t loss 0.2404\n",
      "Epoch 4 \t Iteration 20 \t loss 0.2067\n",
      "Epoch 4 \t Iteration 30 \t loss 0.2998\n",
      "Epoch 4 \t Iteration 40 \t loss 0.3984\n",
      "Epoch 4 \t Iteration 50 \t loss 0.3130\n",
      "test loss: 32.9674 \t epoch 4\n",
      "Best: val loss: 25.4002 \t test loss: 25.4002 \t epoch 3\n",
      "Epoch 5 \t Iteration 0 \t loss 0.3187\n",
      "Epoch 5 \t Iteration 10 \t loss 0.6952\n",
      "Epoch 5 \t Iteration 20 \t loss 0.5016\n",
      "Epoch 5 \t Iteration 30 \t loss 0.2873\n",
      "Epoch 5 \t Iteration 40 \t loss 0.3424\n",
      "Epoch 5 \t Iteration 50 \t loss 1.3238\n",
      "test loss: 27.9624 \t epoch 5\n",
      "Best: val loss: 25.4002 \t test loss: 25.4002 \t epoch 3\n",
      "Epoch 6 \t Iteration 0 \t loss 0.2775\n",
      "Epoch 6 \t Iteration 10 \t loss 0.1473\n",
      "Epoch 6 \t Iteration 20 \t loss 0.3211\n",
      "Epoch 6 \t Iteration 30 \t loss 0.4843\n",
      "Epoch 6 \t Iteration 40 \t loss 0.3882\n",
      "Epoch 6 \t Iteration 50 \t loss 0.4549\n",
      "test loss: 45.2094 \t epoch 6\n",
      "Best: val loss: 25.4002 \t test loss: 25.4002 \t epoch 3\n",
      "Epoch 7 \t Iteration 0 \t loss 1.4093\n",
      "Epoch 7 \t Iteration 10 \t loss 0.1631\n",
      "Epoch 7 \t Iteration 20 \t loss 4.8930\n",
      "Epoch 7 \t Iteration 30 \t loss 0.6958\n",
      "Epoch 7 \t Iteration 40 \t loss 1.2329\n",
      "Epoch 7 \t Iteration 50 \t loss 1.1488\n",
      "test loss: 42.8032 \t epoch 7\n",
      "Best: val loss: 25.4002 \t test loss: 25.4002 \t epoch 3\n",
      "Epoch 8 \t Iteration 0 \t loss 0.4188\n",
      "Epoch 8 \t Iteration 10 \t loss 16.8150\n",
      "Epoch 8 \t Iteration 20 \t loss 1.3438\n",
      "Epoch 8 \t Iteration 30 \t loss 6.5736\n",
      "Epoch 8 \t Iteration 40 \t loss 1.4068\n",
      "Epoch 8 \t Iteration 50 \t loss 1.0481\n",
      "test loss: 213.3407 \t epoch 8\n",
      "Best: val loss: 25.4002 \t test loss: 25.4002 \t epoch 3\n",
      "Epoch 9 \t Iteration 0 \t loss 0.5261\n",
      "Epoch 9 \t Iteration 10 \t loss 1.3358\n",
      "Epoch 9 \t Iteration 20 \t loss 1.9128\n",
      "Epoch 9 \t Iteration 30 \t loss 1.2041\n",
      "Epoch 9 \t Iteration 40 \t loss 0.6251\n",
      "Epoch 9 \t Iteration 50 \t loss 0.2324\n",
      "test loss: 15.8600 \t epoch 9\n",
      "Best: val loss: 15.8600 \t test loss: 15.8600 \t epoch 9\n",
      "Epoch 10 \t Iteration 0 \t loss 0.1274\n",
      "Epoch 10 \t Iteration 10 \t loss 0.7266\n",
      "Epoch 10 \t Iteration 20 \t loss 0.1412\n",
      "Epoch 10 \t Iteration 30 \t loss 0.2543\n",
      "Epoch 10 \t Iteration 40 \t loss 0.3132\n",
      "Epoch 10 \t Iteration 50 \t loss 0.1728\n",
      "test loss: 14.5024 \t epoch 10\n",
      "Best: val loss: 14.5024 \t test loss: 14.5024 \t epoch 10\n",
      "Epoch 11 \t Iteration 0 \t loss 0.0973\n",
      "Epoch 11 \t Iteration 10 \t loss 0.1677\n",
      "Epoch 11 \t Iteration 20 \t loss 0.2153\n",
      "Epoch 11 \t Iteration 30 \t loss 0.1067\n",
      "Epoch 11 \t Iteration 40 \t loss 0.1165\n",
      "Epoch 11 \t Iteration 50 \t loss 0.1153\n",
      "test loss: 13.7350 \t epoch 11\n",
      "Best: val loss: 13.7350 \t test loss: 13.7350 \t epoch 11\n",
      "Epoch 12 \t Iteration 0 \t loss 0.2267\n",
      "Epoch 12 \t Iteration 10 \t loss 0.0867\n",
      "Epoch 12 \t Iteration 20 \t loss 0.1312\n",
      "Epoch 12 \t Iteration 30 \t loss 0.0785\n",
      "Epoch 12 \t Iteration 40 \t loss 0.2458\n",
      "Epoch 12 \t Iteration 50 \t loss 0.0950\n",
      "test loss: 9.1093 \t epoch 12\n",
      "Best: val loss: 9.1093 \t test loss: 9.1093 \t epoch 12\n",
      "Epoch 13 \t Iteration 0 \t loss 0.2790\n",
      "Epoch 13 \t Iteration 10 \t loss 0.4073\n",
      "Epoch 13 \t Iteration 20 \t loss 0.2123\n",
      "Epoch 13 \t Iteration 30 \t loss 0.0645\n",
      "Epoch 13 \t Iteration 40 \t loss 0.1249\n",
      "Epoch 13 \t Iteration 50 \t loss 0.1113\n",
      "test loss: 8.0140 \t epoch 13\n",
      "Best: val loss: 8.0140 \t test loss: 8.0140 \t epoch 13\n",
      "Epoch 14 \t Iteration 0 \t loss 0.1173\n",
      "Epoch 14 \t Iteration 10 \t loss 0.3772\n",
      "Epoch 14 \t Iteration 20 \t loss 0.2241\n",
      "Epoch 14 \t Iteration 30 \t loss 0.1304\n",
      "Epoch 14 \t Iteration 40 \t loss 0.3589\n",
      "Epoch 14 \t Iteration 50 \t loss 0.0905\n",
      "test loss: 10.4101 \t epoch 14\n",
      "Best: val loss: 8.0140 \t test loss: 8.0140 \t epoch 13\n",
      "Epoch 15 \t Iteration 0 \t loss 0.0999\n",
      "Epoch 15 \t Iteration 10 \t loss 0.1501\n",
      "Epoch 15 \t Iteration 20 \t loss 0.0522\n",
      "Epoch 15 \t Iteration 30 \t loss 0.0354\n",
      "Epoch 15 \t Iteration 40 \t loss 0.0852\n",
      "Epoch 15 \t Iteration 50 \t loss 0.1149\n",
      "test loss: 6.6198 \t epoch 15\n",
      "Best: val loss: 6.6198 \t test loss: 6.6198 \t epoch 15\n",
      "Epoch 16 \t Iteration 0 \t loss 0.1394\n",
      "Epoch 16 \t Iteration 10 \t loss 0.0826\n",
      "Epoch 16 \t Iteration 20 \t loss 0.0970\n",
      "Epoch 16 \t Iteration 30 \t loss 0.2114\n",
      "Epoch 16 \t Iteration 40 \t loss 0.2885\n",
      "Epoch 16 \t Iteration 50 \t loss 0.3369\n",
      "test loss: 5.5014 \t epoch 16\n",
      "Best: val loss: 5.5014 \t test loss: 5.5014 \t epoch 16\n",
      "Epoch 17 \t Iteration 0 \t loss 0.0358\n",
      "Epoch 17 \t Iteration 10 \t loss 0.0664\n",
      "Epoch 17 \t Iteration 20 \t loss 0.0911\n",
      "Epoch 17 \t Iteration 30 \t loss 0.1332\n",
      "Epoch 17 \t Iteration 40 \t loss 0.0828\n",
      "Epoch 17 \t Iteration 50 \t loss 0.2536\n",
      "test loss: 11.6127 \t epoch 17\n",
      "Best: val loss: 5.5014 \t test loss: 5.5014 \t epoch 16\n",
      "Epoch 18 \t Iteration 0 \t loss 0.4188\n",
      "Epoch 18 \t Iteration 10 \t loss 0.1638\n",
      "Epoch 18 \t Iteration 20 \t loss 0.1056\n",
      "Epoch 18 \t Iteration 30 \t loss 0.2833\n",
      "Epoch 18 \t Iteration 40 \t loss 0.0981\n",
      "Epoch 18 \t Iteration 50 \t loss 1.8547\n",
      "test loss: 140.4305 \t epoch 18\n",
      "Best: val loss: 5.5014 \t test loss: 5.5014 \t epoch 16\n",
      "Epoch 19 \t Iteration 0 \t loss 1.3090\n",
      "Epoch 19 \t Iteration 10 \t loss 0.6968\n",
      "Epoch 19 \t Iteration 20 \t loss 0.4060\n",
      "Epoch 19 \t Iteration 30 \t loss 0.2590\n",
      "Epoch 19 \t Iteration 40 \t loss 0.8625\n",
      "Epoch 19 \t Iteration 50 \t loss 0.9460\n",
      "test loss: 19.6478 \t epoch 19\n",
      "Best: val loss: 5.5014 \t test loss: 5.5014 \t epoch 16\n",
      "Epoch 20 \t Iteration 0 \t loss 0.5837\n",
      "Epoch 20 \t Iteration 10 \t loss 0.2770\n",
      "Epoch 20 \t Iteration 20 \t loss 0.1647\n",
      "Epoch 20 \t Iteration 30 \t loss 0.2408\n",
      "Epoch 20 \t Iteration 40 \t loss 0.0806\n",
      "Epoch 20 \t Iteration 50 \t loss 0.1918\n",
      "test loss: 14.3088 \t epoch 20\n",
      "Best: val loss: 5.5014 \t test loss: 5.5014 \t epoch 16\n",
      "Epoch 21 \t Iteration 0 \t loss 0.3545\n",
      "Epoch 21 \t Iteration 10 \t loss 0.1646\n",
      "Epoch 21 \t Iteration 20 \t loss 0.2323\n",
      "Epoch 21 \t Iteration 30 \t loss 0.4789\n",
      "Epoch 21 \t Iteration 40 \t loss 1.0406\n",
      "Epoch 21 \t Iteration 50 \t loss 0.4694\n",
      "test loss: 6.5879 \t epoch 21\n",
      "Best: val loss: 5.5014 \t test loss: 5.5014 \t epoch 16\n",
      "Epoch 22 \t Iteration 0 \t loss 0.4964\n",
      "Epoch 22 \t Iteration 10 \t loss 0.2755\n",
      "Epoch 22 \t Iteration 20 \t loss 0.0629\n",
      "Epoch 22 \t Iteration 30 \t loss 0.2809\n",
      "Epoch 22 \t Iteration 40 \t loss 0.1864\n",
      "Epoch 22 \t Iteration 50 \t loss 0.7250\n",
      "test loss: 16.4571 \t epoch 22\n",
      "Best: val loss: 5.5014 \t test loss: 5.5014 \t epoch 16\n",
      "Epoch 23 \t Iteration 0 \t loss 0.0412\n",
      "Epoch 23 \t Iteration 10 \t loss 0.1017\n",
      "Epoch 23 \t Iteration 20 \t loss 0.2227\n",
      "Epoch 23 \t Iteration 30 \t loss 0.0765\n",
      "Epoch 23 \t Iteration 40 \t loss 0.0661\n",
      "Epoch 23 \t Iteration 50 \t loss 0.1261\n",
      "test loss: 10.4584 \t epoch 23\n",
      "Best: val loss: 5.5014 \t test loss: 5.5014 \t epoch 16\n",
      "Epoch 24 \t Iteration 0 \t loss 0.0576\n",
      "Epoch 24 \t Iteration 10 \t loss 0.0611\n",
      "Epoch 24 \t Iteration 20 \t loss 0.1262\n",
      "Epoch 24 \t Iteration 30 \t loss 0.0630\n",
      "Epoch 24 \t Iteration 40 \t loss 0.0961\n",
      "Epoch 24 \t Iteration 50 \t loss 0.1496\n",
      "test loss: 5.7237 \t epoch 24\n",
      "Best: val loss: 5.5014 \t test loss: 5.5014 \t epoch 16\n",
      "Epoch 25 \t Iteration 0 \t loss 0.0506\n",
      "Epoch 25 \t Iteration 10 \t loss 0.0950\n",
      "Epoch 25 \t Iteration 20 \t loss 0.0367\n",
      "Epoch 25 \t Iteration 30 \t loss 0.0421\n",
      "Epoch 25 \t Iteration 40 \t loss 0.0688\n",
      "Epoch 25 \t Iteration 50 \t loss 0.0401\n",
      "test loss: 4.5942 \t epoch 25\n",
      "Best: val loss: 4.5942 \t test loss: 4.5942 \t epoch 25\n",
      "Epoch 26 \t Iteration 0 \t loss 0.0425\n",
      "Epoch 26 \t Iteration 10 \t loss 0.0582\n",
      "Epoch 26 \t Iteration 20 \t loss 0.2550\n",
      "Epoch 26 \t Iteration 30 \t loss 0.0446\n",
      "Epoch 26 \t Iteration 40 \t loss 0.2677\n",
      "Epoch 26 \t Iteration 50 \t loss 0.3617\n",
      "test loss: 9.0655 \t epoch 26\n",
      "Best: val loss: 4.5942 \t test loss: 4.5942 \t epoch 25\n",
      "Epoch 27 \t Iteration 0 \t loss 0.0748\n",
      "Epoch 27 \t Iteration 10 \t loss 0.3846\n",
      "Epoch 27 \t Iteration 20 \t loss 0.3172\n",
      "Epoch 27 \t Iteration 30 \t loss 0.3731\n",
      "Epoch 27 \t Iteration 40 \t loss 0.1288\n",
      "Epoch 27 \t Iteration 50 \t loss 0.7039\n",
      "test loss: 26.7630 \t epoch 27\n",
      "Best: val loss: 4.5942 \t test loss: 4.5942 \t epoch 25\n",
      "Epoch 28 \t Iteration 0 \t loss 0.1348\n",
      "Epoch 28 \t Iteration 10 \t loss 0.5709\n",
      "Epoch 28 \t Iteration 20 \t loss 0.2619\n",
      "Epoch 28 \t Iteration 30 \t loss 0.1358\n",
      "Epoch 28 \t Iteration 40 \t loss 0.1391\n",
      "Epoch 28 \t Iteration 50 \t loss 0.0462\n",
      "test loss: 25.1736 \t epoch 28\n",
      "Best: val loss: 4.5942 \t test loss: 4.5942 \t epoch 25\n",
      "Epoch 29 \t Iteration 0 \t loss 0.0511\n",
      "Epoch 29 \t Iteration 10 \t loss 0.1759\n",
      "Epoch 29 \t Iteration 20 \t loss 0.5003\n",
      "Epoch 29 \t Iteration 30 \t loss 0.0949\n",
      "Epoch 29 \t Iteration 40 \t loss 0.1677\n",
      "Epoch 29 \t Iteration 50 \t loss 0.1765\n",
      "test loss: 23.5131 \t epoch 29\n",
      "Best: val loss: 4.5942 \t test loss: 4.5942 \t epoch 25\n"
     ]
    }
   ],
   "source": [
    "def train(epoch, loader):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for i, data in enumerate(loader):\n",
    "        conversion = convert_to_dense(data, device, dtype)\n",
    "\n",
    "        one_hot_s = conversion[0]\n",
    "        one_hot_t = conversion[1]\n",
    "        edges_s = conversion[2]\n",
    "        edges_t = conversion[3]\n",
    "        atom_mask_s = conversion[4]\n",
    "        atom_mask_t = conversion[5]\n",
    "        edge_mask_s = conversion[6]\n",
    "        edge_mask_t = conversion[7]\n",
    "        n_nodes_s = conversion[8]\n",
    "        n_nodes_t = conversion[9]\n",
    "        atom_positions_s = conversion[10]\n",
    "        atom_positions_t = conversion[11]\n",
    "        batch_size_s = conversion[12]\n",
    "        label = conversion[13]\n",
    "\n",
    "        pred = model(\n",
    "            h0 = [one_hot_s, one_hot_t], \n",
    "            all_edges = [edges_s, edges_t], \n",
    "            all_edge_attr = [None, None], \n",
    "            node_masks = [atom_mask_s, atom_mask_t], \n",
    "            edge_masks = [edge_mask_s, edge_mask_t],\n",
    "            n_nodes = [n_nodes_s, n_nodes_t], \n",
    "            x = [atom_positions_s, atom_positions_t]\n",
    "        )\n",
    "        loss = criterion(pred, label)  # Compute the loss.\n",
    "        epoch_loss += loss.item() * batch_size_s\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch %d \\t Iteration %d \\t loss %.4f\" % (epoch, i, loss.item()))\n",
    "    return epoch_loss/len(loader)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        conversion = convert_to_dense(data, device, dtype)\n",
    "\n",
    "        one_hot_s = conversion[0]\n",
    "        one_hot_t = conversion[1]\n",
    "        edges_s = conversion[2]\n",
    "        edges_t = conversion[3]\n",
    "        atom_mask_s = conversion[4]\n",
    "        atom_mask_t = conversion[5]\n",
    "        edge_mask_s = conversion[6]\n",
    "        edge_mask_t = conversion[7]\n",
    "        n_nodes_s = conversion[8]\n",
    "        n_nodes_t = conversion[9]\n",
    "        atom_positions_s = conversion[10]\n",
    "        atom_positions_t = conversion[11]\n",
    "        batch_size_s = conversion[12]\n",
    "        label = conversion[13]\n",
    "\n",
    "        pred = model(\n",
    "            h0 = [one_hot_s, one_hot_t], \n",
    "            all_edges = [edges_s, edges_t], \n",
    "            all_edge_attr = [None, None], \n",
    "            node_masks = [atom_mask_s, atom_mask_t], \n",
    "            edge_masks = [edge_mask_s, edge_mask_t],\n",
    "            n_nodes = [n_nodes_s, n_nodes_t], \n",
    "            x = [atom_positions_s, atom_positions_t]\n",
    "        )\n",
    "\n",
    "        # epoch_loss += criterion(pred, (label - prop_mean) / prop_mad).item()*batch_size\n",
    "        epoch_loss += criterion(pred, label).item()*batch_size_s\n",
    "    return epoch_loss /len(loader)\n",
    "\n",
    "\n",
    "res = {'epochs': [], 'train_loss': [],'test_loss': [], 'best_val': 1e10, 'best_test': 1e10, 'best_epoch': 0}\n",
    "for epoch in range(0, n_epochs):\n",
    "    train_loss = train(epoch, train_loader)\n",
    "    res['train_loss'].append(train_loss)\n",
    "    if epoch % 1 == 0:\n",
    "        test_loss = test(test_loader)\n",
    "        res['epochs'].append(epoch)\n",
    "        res['test_loss'].append(test_loss)\n",
    "        if test_loss < res['best_val']:\n",
    "            res['best_val'] = test_loss\n",
    "            res['best_test'] = test_loss\n",
    "            res['best_epoch'] = epoch\n",
    "        print(\"test loss: %.4f \\t epoch %d\" % (test_loss, epoch))\n",
    "        print(\"Best: val loss: %.4f \\t test loss: %.4f \\t epoch %d\" % (res['best_val'], res['best_test'], res['best_epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, loader):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for i, data in enumerate(loader):\n",
    "        conversion = convert_to_dense(data, device, dtype)\n",
    "\n",
    "        one_hot_s = conversion[0]\n",
    "        one_hot_t = conversion[1]\n",
    "        edges_s = conversion[2]\n",
    "        edges_t = conversion[3]\n",
    "        atom_mask_s = conversion[4]\n",
    "        atom_mask_t = conversion[5]\n",
    "        edge_mask_s = conversion[6]\n",
    "        edge_mask_t = conversion[7]\n",
    "        n_nodes_s = conversion[8]\n",
    "        n_nodes_t = conversion[9]\n",
    "        atom_positions_s = conversion[10]\n",
    "        atom_positions_t = conversion[11]\n",
    "        batch_size_s = conversion[12]\n",
    "        label = conversion[13]\n",
    "\n",
    "        pred = model(\n",
    "            h0 = [one_hot_s, one_hot_t], \n",
    "            all_edges = [edges_s, edges_t], \n",
    "            all_edge_attr = [None, None], \n",
    "            node_masks = [atom_mask_s, atom_mask_t], \n",
    "            edge_masks = [edge_mask_s, edge_mask_t],\n",
    "            n_nodes = [n_nodes_s, n_nodes_t], \n",
    "            x = [atom_positions_s, atom_positions_t]\n",
    "        )\n",
    "        loss = criterion(pred, label)  # Compute the loss.\n",
    "        epoch_loss += loss.item() * batch_size_s\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch %d \\t Iteration %d \\t loss %.4f\" % (epoch, i, loss.item()))\n",
    "    return epoch_loss/len(loader)\n",
    "\n",
    "res = {'epochs': [], 'train_loss': [],'test_loss': [], 'best_val': 1e10, 'best_test': 1e10, 'best_epoch': 0}\n",
    "for epoch in range(0, n_epochs):\n",
    "    train_loss = train(epoch, train_loader)\n",
    "    res['train_loss'].append(train_loss)\n",
    "    if epoch % 1 == 0:\n",
    "        test_loss = test(test_loader)\n",
    "        res['epochs'].append(epoch)\n",
    "        res['test_loss'].append(test_loss)\n",
    "        if test_loss < res['best_val']:\n",
    "            res['best_val'] = test_loss\n",
    "            res['best_test'] = test_loss\n",
    "            res['best_epoch'] = epoch\n",
    "        print(\"test loss: %.4f \\t epoch %d\" % (test_loss, epoch))\n",
    "        print(\"Best: val loss: %.4f \\t test loss: %.4f \\t epoch %d\" % (res['best_val'], res['best_test'], res['best_epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/raid6/homes/kierannp/projects/multi-egnn/notebooks/cof.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brahman/raid6/homes/kierannp/projects/multi-egnn/notebooks/cof.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(predictions, actuals, \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m,alpha\u001b[39m=\u001b[39m\u001b[39m.2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brahman/raid6/homes/kierannp/projects/multi-egnn/notebooks/cof.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39marange(\u001b[39m-\u001b[39m\u001b[39m15\u001b[39m,\u001b[39m0\u001b[39m),np\u001b[39m.\u001b[39marange(\u001b[39m-\u001b[39m\u001b[39m15\u001b[39m,\u001b[39m0\u001b[39m),\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(predictions, actuals, '.',alpha=.2)\n",
    "plt.plot(np.arange(-15,0),np.arange(-15,0),'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48519"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "dtype = torch.float32\n",
    "df = pd.read_excel('./cloud_point.xlsx')\n",
    "df = df.drop_duplicates().dropna()\n",
    "dat = Cloud_Point_Dataset(root='.',dataframe=df)\n",
    "\n",
    "batch_size = 16\n",
    "loader = DataLoader(dat, batch_size=batch_size, follow_batch=['x_s', 'x_t', 'positions_s', 'positions_t'], shuffle=True)\n",
    "\n",
    "model = MEGNN(n_graphs=2, in_node_nf=7, in_edge_nf=0, hidden_nf=64, device=device, n_layers=7, coords_weight=1.0,\n",
    "             attention=True, node_attr=1, n_enviro=4)\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model = model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9491b3946e3dae68dc71ad961ff18d0345229deb30198fdbd70c8f9ebcae2084"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
